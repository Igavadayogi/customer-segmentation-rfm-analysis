{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097da4c-b50c-45a4-8518-6cf71b7262ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0858e81-4423-4124-b914-4f4f0252256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 1: Data Loading & Cleaning ===\n",
    "df = pd.read_csv('online_retail.csv', encoding='ISO-8859-1')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6aea82-9e4c-4efa-8e32-f7020a0c1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698773e-0adc-4715-a28b-8a5cec3b6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names and data types\n",
    "# Check if InvoiceDate showing as object or datetime\n",
    "print(\"Column Information:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7fcbc-6513-468f-8647-f2af97b7a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values Count:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n% of Missing Values:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48423b-12fb-45a7-bf8a-031af6c3f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16f0a0-7f19-40d1-a0de-9aa7d3379235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning (always preserve original)\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(f\"Starting with {len(df_clean)} rows\")\n",
    "\n",
    "# Remove rows with missing CustomerID\n",
    "df_clean = df_clean[df_clean['CustomerID'].notna()]\n",
    "print(f\"After removing missing CustomerID: {len(df_clean)} rows\")\n",
    "\n",
    "# Remove negative quantities (returns/cancellations)\n",
    "df_clean = df_clean[df_clean['Quantity'] > 0]\n",
    "print(f\"After removing negative quantities: {len(df_clean)} rows\")\n",
    "\n",
    "# Step 3: Remove negative prices (data errors)\n",
    "df_clean = df_clean[df_clean['UnitPrice'] > 0]\n",
    "print(f\"After removing negative prices: {len(df_clean)} rows\")\n",
    "\n",
    "print(f\"\\nFinal clean dataset: {len(df_clean)} rows\")\n",
    "print(f\"Removed {len(df) - len(df_clean)} rows ({((len(df) - len(df_clean))/len(df)*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48223e-403b-4216-b7c5-5c9ebb988ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TotalPrice column (this is the actual revenue per line item)\n",
    "df_clean['TotalPrice'] = df_clean['Quantity'] * df_clean['UnitPrice']\n",
    "\n",
    "print(\"TotalPrice column created!\")\n",
    "print(\"\\nSample of TotalPrice calculation:\")\n",
    "print(df_clean[['Quantity', 'UnitPrice', 'TotalPrice']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb258804-d698-4329-b75e-70a633cec044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert InvoiceDate to datetime format\n",
    "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
    "\n",
    "print(\"InvoiceDate converted to datetime!\")\n",
    "print(f\"Date range: {df_clean['InvoiceDate'].min()} to {df_clean['InvoiceDate'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da5b1f-a7d6-4c50-932c-1037996d9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check - make sure everything looks good\n",
    "print(\"=== CLEANED DATASET SUMMARY ===\")\n",
    "print(f\"\\nTotal rows: {len(df_clean)}\")\n",
    "print(f\"Total columns: {len(df_clean.columns)}\")\n",
    "print(f\"\\nUnique customers: {df_clean['CustomerID'].nunique()}\")\n",
    "print(f\"Unique invoices: {df_clean['InvoiceNo'].nunique()}\")\n",
    "print(f\"Date range: {df_clean['InvoiceDate'].min().date()} to {df_clean['InvoiceDate'].max().date()}\")\n",
    "print(f\"\\nTotal revenue: ${df_clean['TotalPrice'].sum():,.2f}\")\n",
    "print(f\"Average order value: ${df_clean.groupby('InvoiceNo')['TotalPrice'].sum().mean():,.2f}\")\n",
    "\n",
    "print(\"\\n Phase 1 Complete - Data is clean and ready for RFM analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046775c1-877b-4016-a7c2-c2d4711d9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 2: RFM Calculation ===\n",
    "# Define Analysis Date\n",
    "\n",
    "# Find the most recent transaction date in our dataset\n",
    "max_date = df_clean['InvoiceDate'].max()\n",
    "print(f\"Most recent transaction in dataset: {max_date}\")\n",
    "\n",
    "# Set analysis date as 1 day after the most recent transaction\n",
    "# This becomes our \"today\" for calculating recency\n",
    "analysis_date = max_date + pd.Timedelta(days=1)\n",
    "print(f\"Analysis date (our 'today'): {analysis_date}\")\n",
    "print(f\"Analysis date (simplified): {analysis_date.date()}\")\n",
    "\n",
    "print(\"\\n Analysis date set - ready to calculate Recency!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd7fee-1e4e-4784-be19-625042c05f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Calculate RFM Values ===\n",
    "\n",
    "print(\"Calculating RFM metrics for each customer...\\n\")\n",
    "\n",
    "# Group all transactions by customer and calculate behavioral metrics\n",
    "rfm = df_clean.groupby('CustomerID').agg({\n",
    "    # Recency: Days between their LAST purchase and our analysis date\n",
    "    'InvoiceDate': lambda x: (analysis_date - x.max()).days,\n",
    "\n",
    "    # Frequency: COUNT of unique invoices (not total items, but number of orders)\n",
    "    'InvoiceNo': 'nunique',  \n",
    "    \n",
    "    # Monetary: SUM of all their spending across all transactions\n",
    "    'TotalPrice': 'sum'                                       \n",
    "})\n",
    "\n",
    "# Rename columns to be clear\n",
    "rfm.columns = ['Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# Convert index to column for easier manipulation\n",
    "rfm = rfm.reset_index()\n",
    "\n",
    "print(f\"RFM calculated for {len(rfm)} customers\")\n",
    "print(f\"\\nFirst 5 customers:\")\n",
    "print(rfm.head())\n",
    "\n",
    "print(f\"\\nBasic statistics of RFM values:\")\n",
    "print(rfm.describe())\n",
    "\n",
    "print(\"\\n‚úÖ Raw RFM values calculated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528cb07-ed89-406b-b084-24fdb0583928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Assign RFM Scores (1-5 scale using quintiles) ===\n",
    "\n",
    "print(\"Assigning RFM scores (1-5 scale based on quintiles)...\\n\")\n",
    "\n",
    "# For Recency: Lower is better, so we REVERSE the labels\n",
    "# 1 day ago = Score 5 (best), 300 days ago = Score 1 (worst)\n",
    "try:\n",
    "    rfm['R_Score'] = pd.qcut(rfm['Recency'], q=5, labels=[5, 4, 3, 2, 1])\n",
    "except ValueError:\n",
    "    # If exact quintiles don't work, use rank-based scoring instead\n",
    "    rfm['R_Score'] = pd.qcut(rfm['Recency'].rank(method='first'), q=5, labels=[5, 4, 3, 2, 1])\n",
    "\n",
    "# For Frequency: Higher is better, normal labels\n",
    "# 100 purchases = Score 5 (best), 1 purchase = Score 1 (worst)\n",
    "try:\n",
    "    rfm['F_Score'] = pd.qcut(rfm['Frequency'], q=5, labels=[1, 2, 3, 4, 5])\n",
    "except ValueError:\n",
    "    # If exact quintiles don't work, use rank-based scoring instead\n",
    "    rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method='first'), q=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# For Monetary: Higher is better, normal labels\n",
    "# $10,000 spent = Score 5 (best), $10 spent = Score 1 (worst)\n",
    "try:\n",
    "    rfm['M_Score'] = pd.qcut(rfm['Monetary'], q=5, labels=[1, 2, 3, 4, 5])\n",
    "except ValueError:\n",
    "    # If exact quintiles don't work, use rank-based scoring instead\n",
    "    rfm['M_Score'] = pd.qcut(rfm['Monetary'].rank(method='first'), q=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Create RFM_Score as concatenated string (e.g., \"555\" = best customer)\n",
    "rfm['RFM_Score'] = rfm['R_Score'].astype(str) + rfm['F_Score'].astype(str) + rfm['M_Score'].astype(str)\n",
    "\n",
    "print(f\"RFM Scores assigned!\")\n",
    "print(f\"\\nSample of customers with scores:\")\n",
    "print(rfm[['CustomerID', 'Recency', 'Frequency', 'Monetary', 'R_Score', 'F_Score', 'M_Score', 'RFM_Score']].head(10))\n",
    "\n",
    "print(f\"\\nDistribution of R_Score:\")\n",
    "print(rfm['R_Score'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDistribution of F_Score:\")\n",
    "print(rfm['F_Score'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDistribution of M_Score:\")\n",
    "print(rfm['M_Score'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n‚úÖ RFM Scoring complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08622aa0-fafe-4bd7-a11e-85c2fb24a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Validation and Exploration ===\n",
    "\n",
    "print(\"=== RFM CALCULATION SUMMARY ===\\n\")\n",
    "\n",
    "# Basic counts\n",
    "print(f\"Total customers analyzed: {len(rfm)}\")\n",
    "print(f\"Date range of analysis: {df_clean['InvoiceDate'].min().date()} to {df_clean['InvoiceDate'].max().date()}\")\n",
    "\n",
    "# RFM value ranges\n",
    "print(f\"\\nRecency range: {rfm['Recency'].min()} to {rfm['Recency'].max()} days\")\n",
    "print(f\"Frequency range: {rfm['Frequency'].min()} to {rfm['Frequency'].max()} purchases\")\n",
    "print(f\"Monetary range: ${rfm['Monetary'].min():.2f} to ${rfm['Monetary'].max():.2f}\")\n",
    "\n",
    "# Find best customers (RFM = 555)\n",
    "best_customers = rfm[rfm['RFM_Score'] == '555']\n",
    "print(f\"\\nüèÜ Best customers (555 score): {len(best_customers)}\")\n",
    "if len(best_customers) > 0:\n",
    "    print(best_customers[['CustomerID', 'Recency', 'Frequency', 'Monetary']].head())\n",
    "\n",
    "# Find worst customers (RFM = 111)\n",
    "worst_customers = rfm[rfm['RFM_Score'] == '111']\n",
    "print(f\"\\n‚ö†Ô∏è  At-risk customers (111 score): {len(worst_customers)}\")\n",
    "if len(worst_customers) > 0:\n",
    "    print(worst_customers[['CustomerID', 'Recency', 'Frequency', 'Monetary']].head())\n",
    "\n",
    "# Top 10 customers by Monetary value\n",
    "print(f\"\\nüí∞ Top 10 customers by total spending:\")\n",
    "top_spenders = rfm.nlargest(10, 'Monetary')[['CustomerID', 'Recency', 'Frequency', 'Monetary', 'RFM_Score']]\n",
    "print(top_spenders)\n",
    "\n",
    "# Distribution of RFM scores\n",
    "print(f\"\\nüìä Most common RFM score combinations:\")\n",
    "print(rfm['RFM_Score'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n‚úÖ Phase 2 Complete - RFM values calculated and scored!\")\n",
    "print(\"\\nüéØ Ready for Phase 3: Customer Segmentation (Clustering)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5620c-2705-4255-ac03-c65566d1a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE RFM DATA ===\n",
    "\n",
    "# Save to CSV for future use\n",
    "rfm.to_csv('rfm_data.csv', index=False)\n",
    "print(\"‚úÖ RFM data saved to 'rfm_data.csv'\")\n",
    "\n",
    "# Also keep it in memory for Phase 3\n",
    "print(f\"‚úÖ RFM dataframe ready in variable 'rfm' with {len(rfm)} customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77416ab-0ef9-4d31-8468-350ccec3c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 3: Customer Segmentation (K-Means Clustering) ===\n",
    "# Prepare Data for Clustering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"Preparing data for clustering...\\n\")\n",
    "\n",
    "# Select only the RFM columns (not the scores, not CustomerID)\n",
    "rfm_values = rfm[['Recency', 'Frequency', 'Monetary']].copy()\n",
    "\n",
    "print(f\"Selected {len(rfm_values)} customers with 3 features (R, F, M)\")\n",
    "print(f\"\\nBefore normalization - value ranges:\")\n",
    "print(rfm_values.describe())\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "# This converts all values to have mean=0 and std=1\n",
    "scaler = StandardScaler()\n",
    "rfm_normalized = scaler.fit_transform(rfm_values)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "rfm_normalized_df = pd.DataFrame(rfm_normalized, columns=['Recency', 'Frequency', 'Monetary'])\n",
    "\n",
    "print(f\"\\nAfter normalization - all features now on same scale:\")\n",
    "print(rfm_normalized_df.describe())\n",
    "\n",
    "print(\"\\n‚úÖ Data normalized and ready for clustering!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f205c-9d60-48a2-8e4a-1e041279c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Determine Optimal Number of Clusters ===\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "print(\"Testing different numbers of clusters...\\n\")\n",
    "\n",
    "# Test k from 2 to 10\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(rfm_normalized)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(rfm_normalized, kmeans.labels_))\n",
    "    \n",
    "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette Score={silhouette_scores[-1]:.3f}\")\n",
    "\n",
    "# Plot Elbow Method\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, inertias, 'bo-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
    "plt.title('Elbow Method - Looking for the \"Elbow\"')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Silhouette Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range, silhouette_scores, 'ro-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score - Higher is Better')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('optimal_clusters.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Plots saved as 'optimal_clusters.png'\")\n",
    "print(f\"\\nüí° Recommendation: Look for k where:\")\n",
    "print(f\"   - Elbow curve starts to flatten (diminishing returns)\")\n",
    "print(f\"   - Silhouette score is reasonably high\")\n",
    "print(f\"   - Business constraint: 4-6 clusters preferred\")\n",
    "\n",
    "print(\"\\n‚úÖ Cluster optimization analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6209fd-b8fb-4310-94af-2be9f5157df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run K-Means Clustering ===\n",
    "\n",
    "# DECISION: Choose k based on elbow + silhouette + business need\n",
    "# For this example, we'll use k=5 (you can change this after seeing the plots)\n",
    "optimal_k = 5\n",
    "\n",
    "print(f\"Running K-Means with k={optimal_k} clusters...\\n\")\n",
    "\n",
    "# Run final K-Means\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "rfm['Cluster'] = kmeans_final.fit_predict(rfm_normalized)\n",
    "\n",
    "print(f\"Clustering complete!\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(rfm['Cluster'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nSample of customers with cluster assignments:\")\n",
    "print(rfm[['CustomerID', 'Recency', 'Frequency', 'Monetary', 'RFM_Score', 'Cluster']].head(10))\n",
    "\n",
    "print(\"\\n‚úÖ Customers assigned to clusters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdad8c2-22a3-438e-be13-6909f218155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Profile Each Segment ===\n",
    "\n",
    "print(\"Profiling each cluster...\\n\")\n",
    "\n",
    "# Calculate average RFM values for each cluster\n",
    "cluster_profile = rfm.groupby('Cluster').agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'Monetary': ['mean', 'sum'],\n",
    "    'CustomerID': 'count'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "cluster_profile.columns = ['Recency_Avg', 'Frequency_Avg', 'Monetary_Avg', 'Monetary_Total', 'Customer_Count']\n",
    "\n",
    "# Calculate % of total revenue\n",
    "total_revenue = rfm['Monetary'].sum()\n",
    "cluster_profile['Revenue_%'] = (cluster_profile['Monetary_Total'] / total_revenue * 100).round(1)\n",
    "\n",
    "# Calculate % of total customers\n",
    "total_customers = len(rfm)\n",
    "cluster_profile['Customer_%'] = (cluster_profile['Customer_Count'] / total_customers * 100).round(1)\n",
    "\n",
    "print(\"Cluster Profiles:\")\n",
    "print(cluster_profile)\n",
    "print(f\"\\n{'='*80}\")\n",
    "\n",
    "# Also show RFM_Score distribution within each cluster\n",
    "print(\"\\nMost common RFM scores in each cluster:\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    top_scores = rfm[rfm['Cluster']==i]['RFM_Score'].value_counts().head(3)\n",
    "    print(top_scores)\n",
    "\n",
    "print(\"\\n‚úÖ Cluster profiling complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4f4d6-b229-4cd2-8955-f0974b43f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualize Segments ===\n",
    "\n",
    "print(\"Creating segment visualizations...\\n\")\n",
    "\n",
    "# Create scatter plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Recency vs Frequency\n",
    "axes[0, 0].scatter(rfm['Recency'], rfm['Frequency'], c=rfm['Cluster'], cmap='viridis', alpha=0.6)\n",
    "axes[0, 0].set_xlabel('Recency (days)')\n",
    "axes[0, 0].set_ylabel('Frequency (purchases)')\n",
    "axes[0, 0].set_title('Recency vs Frequency by Cluster')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Recency vs Monetary\n",
    "axes[0, 1].scatter(rfm['Recency'], rfm['Monetary'], c=rfm['Cluster'], cmap='viridis', alpha=0.6)\n",
    "axes[0, 1].set_xlabel('Recency (days)')\n",
    "axes[0, 1].set_ylabel('Monetary ($)')\n",
    "axes[0, 1].set_title('Recency vs Monetary by Cluster')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Frequency vs Monetary\n",
    "axes[1, 0].scatter(rfm['Frequency'], rfm['Monetary'], c=rfm['Cluster'], cmap='viridis', alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Frequency (purchases)')\n",
    "axes[1, 0].set_ylabel('Monetary ($)')\n",
    "axes[1, 0].set_title('Frequency vs Monetary by Cluster')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Cluster distribution\n",
    "cluster_counts = rfm['Cluster'].value_counts().sort_index()\n",
    "axes[1, 1].bar(cluster_counts.index, cluster_counts.values, color='skyblue', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Cluster')\n",
    "axes[1, 1].set_ylabel('Number of Customers')\n",
    "axes[1, 1].set_title('Customer Distribution Across Clusters')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('customer_segments_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations created and saved!\")\n",
    "print(\"\\nüéØ Phase 3 Complete - Customer Segments Identified!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db9351-34ff-43e1-be98-39a981aa37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHASE 4: Business Recommendation ===\n",
    "# Assign Business Names to Clusters\n",
    "\n",
    "print(\"Assigning business names to segments...\\n\")\n",
    "\n",
    "# Map cluster numbers to business-friendly names\n",
    "segment_names = {\n",
    "    0: 'Core Customers',\n",
    "    1: 'At-Risk/Lost',\n",
    "    2: 'Champions',\n",
    "    3: 'Super VIPs',\n",
    "    4: 'Mega Whales'\n",
    "}\n",
    "\n",
    "# Add segment name column\n",
    "rfm['Segment'] = rfm['Cluster'].map(segment_names)\n",
    "\n",
    "print(\"Segment distribution:\")\n",
    "print(rfm['Segment'].value_counts())\n",
    "\n",
    "print(f\"\\nSample customers with segment names:\")\n",
    "print(rfm[['CustomerID', 'Recency', 'Frequency', 'Monetary', 'RFM_Score', 'Segment']].head(15))\n",
    "\n",
    "# Save the final segmented data\n",
    "rfm.to_csv('customer_segments_final.csv', index=False)\n",
    "print(\"\\n‚úÖ Segmented data saved to 'customer_segments_final.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c9e69-d95f-4c13-b177-81408cea4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quantify Business Opportunities ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS OPPORTUNITY ANALYSIS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Opportunity 1: Win back At-Risk customers\n",
    "at_risk = rfm[rfm['Segment'] == 'At-Risk/Lost']\n",
    "at_risk_revenue = at_risk['Monetary'].sum()\n",
    "at_risk_avg_spend = at_risk['Monetary'].mean()\n",
    "at_risk_count = len(at_risk)\n",
    "\n",
    "print(\"üéØ OPPORTUNITY 1: Win-Back Campaign for At-Risk Customers\")\n",
    "print(f\"Current state:\")\n",
    "print(f\"  - {at_risk_count} customers haven't purchased in 8+ months\")\n",
    "print(f\"  - Average lifetime value: ${at_risk_avg_spend:.2f}\")\n",
    "print(f\"  - Total potential revenue at risk: ${at_risk_revenue:,.2f}\")\n",
    "print(f\"\\nScenario: Win-back campaign with 15% success rate\")\n",
    "recovered_customers = int(at_risk_count * 0.15)\n",
    "recovered_revenue = recovered_customers * at_risk_avg_spend\n",
    "print(f\"  - Customers recovered: {recovered_customers}\")\n",
    "print(f\"  - Additional annual revenue: ${recovered_revenue:,.2f}\")\n",
    "print(f\"  - ROI if campaign costs $10K: {(recovered_revenue / 10000 - 1) * 100:.0f}%\")\n",
    "\n",
    "# Opportunity 2: Increase Core Customer frequency\n",
    "core = rfm[rfm['Segment'] == 'Core Customers']\n",
    "core_avg_frequency = core['Frequency'].mean()\n",
    "core_avg_monetary = core['Monetary'].mean()\n",
    "core_count = len(core)\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "print(\"üéØ OPPORTUNITY 2: Increase Core Customer Purchase Frequency\")\n",
    "print(f\"Current state:\")\n",
    "print(f\"  - {core_count} customers with avg {core_avg_frequency:.1f} purchases/year\")\n",
    "print(f\"  - Average customer value: ${core_avg_monetary:.2f}\")\n",
    "print(f\"\\nScenario: Increase purchase frequency by 20% (email campaigns, loyalty rewards)\")\n",
    "additional_purchases = core_count * core_avg_frequency * 0.20\n",
    "revenue_per_purchase = core_avg_monetary / core_avg_frequency\n",
    "additional_revenue = additional_purchases * revenue_per_purchase\n",
    "print(f\"  - Additional purchases: {additional_purchases:.0f}\")\n",
    "print(f\"  - Additional annual revenue: ${additional_revenue:,.2f}\")\n",
    "\n",
    "# Opportunity 3: Protect Champions (churn prevention)\n",
    "champions = rfm[rfm['Segment'] == 'Champions']\n",
    "champions_revenue = champions['Monetary'].sum()\n",
    "champions_count = len(champions)\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "print(\"üéØ OPPORTUNITY 3: Champions Retention Program\")\n",
    "print(f\"Current state:\")\n",
    "print(f\"  - {champions_count} Champions generate ${champions_revenue:,.2f} (30.7% of revenue)\")\n",
    "print(f\"  - Industry avg churn: 10-15% annually\")\n",
    "print(f\"\\nScenario: VIP program reduces churn from 12% to 5%\")\n",
    "prevented_churn = champions_count * 0.07  # 7% reduction\n",
    "retained_revenue = (prevented_churn / champions_count) * champions_revenue\n",
    "print(f\"  - Customers retained: {prevented_churn:.0f}\")\n",
    "print(f\"  - Revenue protected: ${retained_revenue:,.2f}\")\n",
    "print(f\"  - ROI if program costs $50K: {(retained_revenue / 50000 - 1) * 100:.0f}%\")\n",
    "\n",
    "# Opportunity 4: Protect Whales\n",
    "whales = rfm[rfm['Segment'].isin(['Super VIPs', 'Mega Whales'])]\n",
    "whales_revenue = whales['Monetary'].sum()\n",
    "whales_count = len(whales)\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "print(\"üéØ OPPORTUNITY 4: White-Glove Service for Top 14 Customers\")\n",
    "print(f\"Current state:\")\n",
    "print(f\"  - {whales_count} customers generate ${whales_revenue:,.2f} (17.9% of revenue)\")\n",
    "print(f\"  - Losing ONE Mega Whale = ${rfm[rfm['Segment']=='Mega Whales']['Monetary'].mean():,.2f} loss\")\n",
    "print(f\"\\nScenario: Dedicated account manager prevents 1 whale churn\")\n",
    "whale_avg_value = whales['Monetary'].mean()\n",
    "print(f\"  - Value protected by preventing 1 churn: ${whale_avg_value:,.2f}\")\n",
    "print(f\"  - ROI if dedicated manager costs $80K/year: {(whale_avg_value / 80000 - 1) * 100:.0f}%\")\n",
    "\n",
    "# Total opportunity summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üí∞ TOTAL ANNUAL OPPORTUNITY SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "total_opportunity = recovered_revenue + additional_revenue + retained_revenue + whale_avg_value\n",
    "print(f\"Win-back campaign:           ${recovered_revenue:>12,.2f}\")\n",
    "print(f\"Frequency increase:          ${additional_revenue:>12,.2f}\")\n",
    "print(f\"Champions retention:         ${retained_revenue:>12,.2f}\")\n",
    "print(f\"Whale protection:            ${whale_avg_value:>12,.2f}\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"TOTAL REVENUE OPPORTUNITY:   ${total_opportunity:>12,.2f}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"‚úÖ Business opportunity analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6156a-01fd-48b7-ae5c-eb97d6ba7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Strategic Recommendations by Segment ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEGMENT-SPECIFIC MARKETING STRATEGIES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create recommendations dictionary\n",
    "strategies = {\n",
    "    'Segment': ['Core Customers', 'At-Risk/Lost', 'Champions', 'Super VIPs', 'Mega Whales'],\n",
    "    'Size': ['3,049 (70.3%)', '1,062 (24.5%)', '213 (4.9%)', '8 (0.2%)', '6 (0.1%)'],\n",
    "    'Revenue_Share': ['45.8%', '5.7%', '30.7%', '5.0%', '12.9%'],\n",
    "    'Marketing_Strategy': [\n",
    "        'Regular email campaigns, product recommendations, seasonal promotions',\n",
    "        'Win-back campaign: \"We miss you\" emails, 20% discount for return',\n",
    "        'VIP loyalty program, early access to new products, exclusive discounts',\n",
    "        'Dedicated account manager, quarterly business reviews, custom solutions',\n",
    "        'Personal relationship with CEO, custom pricing, white-glove service'\n",
    "    ],\n",
    "    'Communication_Frequency': [\n",
    "        'Bi-weekly emails',\n",
    "        'One-time campaign then remove if no response',\n",
    "        'Weekly engagement',\n",
    "        'Monthly check-ins',\n",
    "        'Continuous personal contact'\n",
    "    ],\n",
    "    'Budget_Allocation': [\n",
    "        '40%',\n",
    "        '10%',\n",
    "        '25%',\n",
    "        '10%',\n",
    "        '15%'\n",
    "    ],\n",
    "    'Priority': [\n",
    "        'Medium',\n",
    "        'Low (test campaign only)',\n",
    "        'High',\n",
    "        'Critical',\n",
    "        'Critical'\n",
    "    ]\n",
    "}\n",
    "\n",
    "strategies_df = pd.DataFrame(strategies)\n",
    "\n",
    "print(strategies_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "strategies_df.to_csv('segment_strategies.csv', index=False)\n",
    "print(f\"\\n‚úÖ Strategies saved to 'segment_strategies.csv'\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ PHASE 4 COMPLETE - Business Recommendations Generated!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339742ee-4354-4b25-a5c4-721a64c9b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PORTFOLIO VISUALIZATIONS ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Creating portfolio-ready visualizations...\\n\")\n",
    "\n",
    "# Set style for professional look\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 1: Segment Revenue Contribution (For Portfolio Page 2)\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Data for pie chart\n",
    "segments = ['Core Customers', 'At-Risk/Lost', 'Champions', 'Super VIPs', 'Mega Whales']\n",
    "revenue_pct = [45.8, 5.7, 30.7, 5.0, 12.9]\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "# Create pie chart\n",
    "wedges, texts, autotexts = ax.pie(revenue_pct, \n",
    "                                    labels=segments, \n",
    "                                    autopct='%1.1f%%',\n",
    "                                    colors=colors,\n",
    "                                    startangle=90,\n",
    "                                    textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "\n",
    "# Make percentage text white and bold\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontsize(11)\n",
    "    autotext.set_weight('bold')\n",
    "\n",
    "ax.set_title('Revenue Distribution by Customer Segment', fontsize=16, weight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('segment_revenue_pie.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: segment_revenue_pie.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 2: Segment Profile Heatmap (For Portfolio Page 3)\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create segment profile data (normalized for heatmap)\n",
    "segment_data = {\n",
    "    'Segment': ['Core Customers', 'At-Risk/Lost', 'Champions', 'Super VIPs', 'Mega Whales'],\n",
    "    'Recency_Score': [5, 1, 5, 5, 5],  # Lower recency = higher score\n",
    "    'Frequency_Score': [3, 1, 5, 5, 4],\n",
    "    'Monetary_Score': [2, 1, 5, 5, 5]\n",
    "}\n",
    "\n",
    "# Create matrix for heatmap\n",
    "heatmap_data = []\n",
    "for i in range(len(segment_data['Segment'])):\n",
    "    heatmap_data.append([\n",
    "        segment_data['Recency_Score'][i],\n",
    "        segment_data['Frequency_Score'][i],\n",
    "        segment_data['Monetary_Score'][i]\n",
    "    ])\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(heatmap_data, \n",
    "            annot=True, \n",
    "            fmt='d',\n",
    "            cmap='RdYlGn',\n",
    "            cbar_kws={'label': 'Score (1=Low, 5=High)'},\n",
    "            xticklabels=['Recency', 'Frequency', 'Monetary'],\n",
    "            yticklabels=segment_data['Segment'],\n",
    "            linewidths=2,\n",
    "            linecolor='white',\n",
    "            vmin=1,\n",
    "            vmax=5,\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_title('Customer Segment Profiles (RFM Scores)', fontsize=16, weight='bold', pad=20)\n",
    "ax.set_xlabel('RFM Metrics', fontsize=12, weight='bold')\n",
    "ax.set_ylabel('Customer Segment', fontsize=12, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('segment_profile_heatmap.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: segment_profile_heatmap.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 3: Business Opportunities Bar Chart (For Portfolio Page 3)\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "opportunities = ['Win-Back\\nCampaign', 'Frequency\\nIncrease', 'Champions\\nRetention', 'Whale\\nProtection']\n",
    "values = [76019, 816563, 191321, 113406]\n",
    "colors_bars = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6']\n",
    "\n",
    "bars = ax.bar(opportunities, values, color=colors_bars, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, values)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'${value:,.0f}',\n",
    "            ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "ax.set_ylabel('Annual Revenue Opportunity ($)', fontsize=12, weight='bold')\n",
    "ax.set_title('Identified Business Opportunities', fontsize=16, weight='bold', pad=20)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add total line\n",
    "total = sum(values)\n",
    "ax.axhline(y=total/4, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "ax.text(len(opportunities)-0.5, total/4, f'Total: ${total:,.0f}', \n",
    "        fontsize=11, weight='bold', color='red', \n",
    "        bbox=dict(boxstyle='round', facecolor='white', edgecolor='red'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('business_opportunities_bar.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Saved: business_opportunities_bar.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALL PORTFOLIO VISUALIZATIONS CREATED!\")\n",
    "print(\"=\"*80)\n",
    "print(\"Data:\")\n",
    "print(\"  1. segment_revenue_pie.png\")\n",
    "print(\"  2. segment_profile_heatmap.png\")\n",
    "print(\"  3. business_opportunities_bar.png\")\n",
    "print(\"  4. customer_segments_visualization.png (from Phase 3)\")\n",
    "print(\"  5. optimal_clusters.png (from Phase 3)\")\n",
    "print(\"\\nProject Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52276a-1be5-46f8-8c1f-1bc8978e61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FINAL VALIDATION ===\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SANITY CHECKS - Verify Results Make Business Sense\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Check 1: Do segment sizes add up to total customers?\n",
    "total_customers = len(rfm)\n",
    "segment_sum = rfm['Segment'].value_counts().sum()\n",
    "assert total_customers == segment_sum, \"‚ùå Segment counts don't match total!\"\n",
    "print(f\"‚úÖ Check 1 Passed: {total_customers} customers = {segment_sum} in segments\")\n",
    "\n",
    "# Check 2: Does revenue add up correctly?\n",
    "total_revenue = rfm['Monetary'].sum()\n",
    "segment_revenue = rfm.groupby('Segment')['Monetary'].sum().sum()\n",
    "assert abs(total_revenue - segment_revenue) < 0.01, \"‚ùå Revenue mismatch!\"\n",
    "print(f\"‚úÖ Check 2 Passed: Total revenue ${total_revenue:,.2f} matches segment sum\")\n",
    "\n",
    "# Check 3: Are Champions actually better than At-Risk?\n",
    "champions_avg = rfm[rfm['Segment']=='Champions']['Monetary'].mean()\n",
    "at_risk_avg = rfm[rfm['Segment']=='At-Risk/Lost']['Monetary'].mean()\n",
    "assert champions_avg > at_risk_avg, \"‚ùå Champions should spend more than At-Risk!\"\n",
    "print(f\"‚úÖ Check 3 Passed: Champions (${champions_avg:,.2f}) > At-Risk (${at_risk_avg:,.2f})\")\n",
    "\n",
    "# Check 4: Do the top 5% really generate ~50% of revenue?\n",
    "top_5pct_count = int(len(rfm) * 0.05)\n",
    "top_5pct_revenue = rfm.nlargest(top_5pct_count, 'Monetary')['Monetary'].sum()\n",
    "top_5pct_pct = (top_5pct_revenue / total_revenue) * 100\n",
    "print(f\"‚úÖ Check 4: Top 5% of customers = {top_5pct_pct:.1f}% of revenue (expected ~50%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALL SANITY CHECKS PASSED - Results are valid!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f1457-3dbf-4bb7-9b38-f9c22dd7ecfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
